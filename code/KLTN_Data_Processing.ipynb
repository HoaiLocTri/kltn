{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import enchant\n",
    "import pandas as pd\n",
    "import string\n",
    "# from pyvi import ViTokenizer, ViPosTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đối tượng chứa các hàm xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tvpl_function:\n",
    "    def __init__(self):\n",
    "        self.pattern = 'aàảãáạăằẳẵắặâầẩẫấậeèẻẽéẹêềểễếệiìỉĩíịoòỏõóọôồổỗốộơớờởỡợuùủũúụưừửữứựyỳỷỹýỵđ'\n",
    "\n",
    "        self.words_en = enchant.Dict(\"en_US\")\n",
    "        \n",
    "        self.specialCharset = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "\n",
    "        self.words = []\n",
    "        with open(\"data/words.txt\", \"r\", encoding='utf-8') as file:\n",
    "            for f in file:\n",
    "                word = json.loads(f)\n",
    "                self.words.append(word[\"text\"])\n",
    "\n",
    "        self.syllables = []\n",
    "        with open(\"data/syllable.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                self.syllables.append(line.strip())\n",
    "                \n",
    "        self.mapping={\n",
    "            'óa':'oá', 'òa':'oà', 'ỏa':'oả', 'õa':'oã', 'ọa':'oạ',\n",
    "            'óe':'oé', 'òe':'oè', 'ỏe':'oẻ', 'õe':'oẽ', 'ọe':'oẹ',\n",
    "            'úy':'uý', 'ùy':'uỳ', 'ủy':'uỷ', 'ũy':'uỹ', 'ụy':'uỵ',\n",
    "            'úâ':'uấ', 'ùâ':'uầ', 'ủâ':'uẩ', 'ũâ':'uẫ', 'ụâ':'uậ',\n",
    "            'úe':'ué', 'ùe':'uè', 'ủe':'uẻ', 'ũe':'uẽ', 'ụe':'uẹ',\n",
    "            'úê':'uế', 'ùê':'uề', 'ủê':'uể', 'ũê':'uễ', 'ụê':'uệ',\n",
    "            'úơ':'uớ', 'ùơ':'uờ', 'ủơ':'uở', 'ũơ':'uỡ', 'ụơ':'uợ',\n",
    "            'úô':'uố', 'ùô':'uồ', 'ủô':'uổ', 'ũô':'uỗ', 'ụô':'uộ',\n",
    "            'iá':'ía', 'ià':'ìa', 'iả':'ỉa', 'iã':'ĩa', 'iạ':'ịa',\n",
    "            'yá':'ýa', 'yà':'ỳa', 'yả':'ỷa', 'yã':'ỹa', 'yạ':'ỵa',\n",
    "            'uá':'úa', 'uà':'ùa', 'uả':'ủa', 'uã':'ũa', 'uạ':'ụa',\n",
    "            'ưá':'ứa', 'ưà':'ừa', 'ưả':'ửa', 'ưã':'ữa', 'ưạ':'ựa',\n",
    "            'ứơ':'ướ', 'ừơ':'ườ', 'ửơ':'ưở', 'ữơ':'ưỡ', 'ựơ':'ượ',\n",
    "            'íê':'iế', 'ìê':'iề', 'ỉê':'iể', 'ĩê':'iễ', 'ịê':'iệ',\n",
    "            'ýê':'yế', 'ỳê':'yề', 'ỷê':'yể', 'ỹê':'yễ', 'ỵê':'yệ',\n",
    "            'uí':'úi', 'uì':'ùi', 'uỉ':'ủi', 'uĩ':'ũi', 'uị':'ụi',\n",
    "            'aó':'áo', 'aò':'ào', 'aỏ':'ảo', 'aõ':'ão', 'aọ':'ạo',\n",
    "            'qúa':'quá', 'qùa':'quà', 'qủa':'quả', 'qũa':'quã', 'qụa': 'quạ',\n",
    "            'Qúa':'Quá', 'Qùa':'Quà', 'Qủa':'Quả', 'Qũa':'Quã', 'Qụa': 'Quạ', \n",
    "            'gía':'giá', 'gìa':'già', 'gỉa':'giả', 'gĩa':'giã', 'gịa': 'giạ',\n",
    "            'Gía':'Giá', 'Gìa':'Già', 'Gỉa':'Giả', 'Gĩa':'Giã', 'Gịa': 'Giạ',\n",
    "        }\n",
    "\n",
    "    # chuẩn hóa bảng mã tiếng việt\n",
    "    # Tạo ra từ điện bộ kí tự\n",
    "    def load_DictChar(self):\n",
    "        dic = {}\n",
    "        char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "            '|')\n",
    "        charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "            '|')\n",
    "        for i in range(len(char1252)):\n",
    "            dic[char1252[i]] = charutf8[i]\n",
    "        return dic\n",
    "    \n",
    "    # Chuyển đổi mã kí tự 1252 sang UTF-8\n",
    "    def covert_unicode(self, txt):\n",
    "        dicchar = self.load_DictChar()\n",
    "        return re.sub(\n",
    "            r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "            lambda x: dicchar[x.group()], txt) \n",
    "\n",
    "    # xóa phần không cần thiết trong văn bản\n",
    "    def removeUnnecessaryPart(self, row):\n",
    "        for i, line in enumerate(row.splitlines()):\n",
    "            if re.match(r\"^(PHẦN PHỤ LỤC|DANH MỤC PHỤ LỤC)\", line) or re.match(r\"^phụ lục\", line.lower()) or re.match(r\"^(\\s|\\t)*PHỤ LỤC\", line):\n",
    "                row = '\\n'.join(row.splitlines()[:i])\n",
    "                break     \n",
    "        \n",
    "        return row\n",
    "    \n",
    "    # đổi về chữ thường\n",
    "    def text_lower(self, text):\n",
    "        return text.lower()\n",
    "    \n",
    "    #  Tìm và thay thế các ký tự không in được trong text thành khoảng trắng\n",
    "    def  replace_non_printable_chars(self, row):\n",
    "        return  ''.join(char if char in string.printable or char.lower() in self.pattern else ' ' for char in row)\n",
    "                \n",
    "    def data_processing(self, row):\n",
    "        row = self.covert_unicode(row)                          # Chuẩn hóa bảng mã kí \n",
    "        row = self.removeUnnecessaryPart(row)                   # Loại bỏ phần không cần thiết\n",
    "        row = self.replace_non_printable_chars(row)             # Thay thế các chuỗi không in được thành khoảng trắng\n",
    "        row = self.text_lower(row)                              # Đổi thành chữ thường\n",
    "        \n",
    "        result_line = []\n",
    "        for line in row.splitlines():           \n",
    "            if line != ' ' and line != '':\n",
    "                line = line.replace('\\n', '').replace('\\t', '')                 # Loại \\n và \\t trong dòng\n",
    "                line = self.Handling_Stuck_Syllables(line)                      # Tách âm tiết bị dính nhau\n",
    "                line = ViTokenizer.tokenize(line).lstrip().rstrip()             # Tách câu, tách từ tiếng \n",
    "                result_line.append(line)\n",
    "        row = \"\\n\\n\".join(result_line)\n",
    "\n",
    "        row = row.replace(\" / \", \"/\")\n",
    "        row = row.replace(\" - \", \"-\")\n",
    "\n",
    "        return row\n",
    "        return row\n",
    "\n",
    "    # Chuẩn hóa y và i (vd: tỷ lệ -> tỉ lệ, bác sỹ -> bác sĩ)\n",
    "    def chuan_hoa_y_i(self, word):\n",
    "        set_yi ={1: 'yýỳỷỹỵ', 2: 'iíìỉĩị'}\n",
    "        index_yi = None\n",
    "        index_setyi = None\n",
    "        for i in range(6):\n",
    "            if set_yi[1][i] in word or set_yi[2][i] in word:\n",
    "                index_yi = word.index(set_yi[1][i]) if set_yi[1][i] in word else word.index(set_yi[2][i])\n",
    "                index_setyi = i\n",
    "                break\n",
    "\n",
    "        if index_yi is not None:\n",
    "            if len(word) == 1 and word in set_yi[2]:\n",
    "                word = set_yi[1][index_setyi]\n",
    "            elif (len(word) > 1 and index_yi == len(word) - 1 and word[index_yi] in set_yi[1] \n",
    "            and word[:index_yi] in ['b','c','ch','d','đ','g','gh','h','k','kh','l','m','n','ng','ngh','nh','p','ph','r','s','t','th','tr','v','x']):\n",
    "                word = word[:index_yi] + set_yi[2][index_setyi]\n",
    "\n",
    "        return word\n",
    "\n",
    "    # Xử lý các âm tiết bị lỗi dính nhau trong từng câu của văn bản\n",
    "    def Handling_Stuck_Syllables(self, sentence):\n",
    "        result_sentence = []\n",
    "        sentence = self.split_speicalChar(sentence) # Tách các kí tự đặc biệt (ví dụ: 'luật.' -> 'luật .')\n",
    "        for word in sentence.split():       # xét từng chữ\n",
    "            word = self.standardize_Tone(word)  # Chuẩn hóa thanh điệu\n",
    "            word = self.chuan_hoa_y_i(word)     # Chuẩn hóa y/i\n",
    "            # Nếu từ không chứa kí tự, từ có nghĩa, là số ký hiệu hoặc là từ tiếng anh thì bỏ qua\n",
    "            if (len(word) == 1\n",
    "                    or any(char in word for char in self.specialCharset)\n",
    "                    or any(char in word.lower() for char in [\"f\",\"j\",\"w\",\"z\"])\n",
    "                    or any(char in '0123456789' for char in word)\n",
    "                    or self.words_en.check(word) \n",
    "                    or self.syllable_check(word) \n",
    "                    ):\n",
    "                result_sentence.append(word)\n",
    "                continue\n",
    "\n",
    "            # Từ có nghĩa nhưng có 2 chữ giống nhau liên tiếp (vd: hoaang, luuật)\n",
    "            word = self.double_char(word)\n",
    "            if self.syllable_check(word):   # xét từ có nghĩa chưa\n",
    "                result_sentence.append(word)\n",
    "                continue\n",
    "\n",
    "            check = True\n",
    "            #Kiểm tra cặp từ có nghĩa trong từ điển\n",
    "            for i in range(1, len(word)-1):\n",
    "                text = word[:i] + \" \" + word[i:]\n",
    "                if self.dictionary_check(text):\n",
    "                    check = False\n",
    "                    break\n",
    "                \n",
    "            # Nếu không có cặp từ có nghĩa\n",
    "            if check:\n",
    "                text = self.split_syllable(word)   # text = text (được tách ra)/ False (không được tách)\n",
    "\n",
    "            # Xử lý các âm tiết bị lỗi dính nhau (các trường hợp chữ viết tắt và sai chính tả -> False)\n",
    "            result_sentence.append(text if text else word) # nếu False thì từ được giữ nguyên\n",
    "\n",
    "        return ' '.join(result_sentence)\n",
    "\n",
    "    # Tách các kí tự đặc biệt \n",
    "    def split_speicalChar(self, text):  \n",
    "        for i in self.specialCharset:\n",
    "            if i in text:\n",
    "                text = text.replace(i, f\" {i} \")\n",
    "        return text\n",
    "\n",
    "    # Trả kết quả xử lý tách các âm tiết dính nhau\n",
    "    def split_syllable(self, syllable):\n",
    "        \n",
    "        memories = []\n",
    "        while syllable != '':\n",
    "            text_len = len(syllable)    # Độ dài từ hiện tại\n",
    "            memory = []                 # Chứa các từ có nghĩa \n",
    "            queue = ''                  # Cập nhật các từ\n",
    "\n",
    "            for i in range(text_len):\n",
    "                # Xử lý từ có nghĩa (vd: nóng -> memory = [nó, nón, nóng])\n",
    "                queue += syllable[i]\n",
    "                \n",
    "                # Lọc ra cá kí tự đứng 1 mình, trừ các từ có thể\n",
    "                if len(queue) == 1 and queue not in ['ả', 'ế', 'ô', 'ố', 'ổ', 'y', 'ý', 'ỷ', 'ủ']:\n",
    "                    continue\n",
    "\n",
    "                if self.syllable_check(queue) or self.dictionary_check(queue):\n",
    "                    memory.append(queue)\n",
    "            \n",
    "            # Nếu memory có chứa các từ có nghĩa\n",
    "            if memory:\n",
    "                memories.append(memory)\n",
    "                syllable = syllable[len(memory[-1]):]     # Loại bỏ từ có nghĩa trong chuỗi syllable và xét tiếp theo vòng lặp while\n",
    "            # Nếu không\n",
    "            else:\n",
    "                # Nếu xét cả chuỗi không có từ nào hoặc chỉ 1 từ có nghĩa trong chuỗi -> False\n",
    "                if memories and len(memories[0]) > 1:\n",
    "                    # kiểm tra chuỗi từ trước có 2 từ trở lên thì ghép chữ cuối cùng của chuỗi từ đó [-1]  \n",
    "                    for j in range(len(memories), 0, -1):\n",
    "                        # Vd: hoặcđiago -> memories = [['cá', 'các', 'cách'],['i']] --- syllable = 'ệp'\n",
    "                        if len(memories[j-1]) >= 2:\n",
    "                            syllable = memories[j-1].pop(-1)[-1] + ''.join(c[-1] for c in memories[j:]) + syllable\n",
    "                            memories = memories[:j]\n",
    "                            break\n",
    "                else:\n",
    "                    return False\n",
    "        \n",
    "        return ' '.join(i[-1] for i in memories)\n",
    "\n",
    "    # kiểm tra từ hoặc cụm từ có trong từ điển\n",
    "    def dictionary_check(self, text):\n",
    "        return text.lower() in self.words\n",
    "    \n",
    "    # kiểm tra âm tiết có trong từ điển\n",
    "    def syllable_check(self, syllable):\n",
    "        return syllable.lower() in self.syllables\n",
    "\n",
    "    # xóa các kí tự lặp (trừ \"o\")\n",
    "    def double_char(self, word):\n",
    "        result = word[0]  # Khởi tạo result với ký tự đầu tiên của word\n",
    "        for i in range(1, len(word)):  # Bắt đầu vòng lặp từ chỉ số 1\n",
    "            if result[-1] == word[i] and word[i] != 'o':\n",
    "                continue\n",
    "            result += word[i]\n",
    "\n",
    "        return result\n",
    "\n",
    "    # Chuẩn hóa thanh điệu \n",
    "    def standardize_Tone(self, word):  \n",
    "        if word != \"gịa\" and word != \"quốc\":\n",
    "            for key, value in self.mapping.items():\n",
    "                word = word.replace(key, value)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = 'data/tvpl.csv'\n",
    "df_raw = pd.read_csv(PATH_DATA, encoding='utf-8-sig')\n",
    "\n",
    "# Định dạng cột 'Ngày ban hành'\n",
    "df_raw['Ngày ban hành'] = pd.to_datetime(df_raw['Ngày ban hành'], format='%d/%m/%Y').dt.strftime('ngày %d tháng %m năm %Y')  # định dạng cột 'ngày ban hành'\n",
    "\n",
    "# Loại bỏ các hàng ngoại lệ\n",
    "list_remove = [9,369,2936,3789,4630,5740,6707]                      \n",
    "df_raw = df_raw.drop(index=list_remove).reset_index(drop=True)\n",
    "\n",
    "vb = tvpl_function()\n",
    "\n",
    "column_vb = 'Nội dung'\n",
    "column_qh = 'Mối quan hệ'\n",
    "\n",
    "df_raw.info()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiểm tra giá trị trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_raw.isna().values.any(), df_raw.isnull().values.any())\n",
    "df = df_raw.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[column_vb] = df[column_vb].apply(vb.data_processing)\n",
    "\n",
    "# Đặt tên theo cấu trúc '[loại văn bản] + [số hiệu] + [ngày ban hành] + [cơ quan ban hành]' ở dòng đầu tiên của mỗi văn bản\n",
    "for i in range(len(df)):\n",
    "    title = df.loc[i, 'Loại văn bản'] + ' số ' + df.loc[i, 'Số hiệu'] + ' ' + df.loc[i, 'Ngày ban hành'] + ' của ' + df.loc[i, 'Cơ quan ban hành'] \n",
    "    df.at[i, column_vb] = title + '\\n\\n' + df.at[i, column_vb]\n",
    "\n",
    "type_documents = {\n",
    "    ' Hiến_pháp ': 'HP',\n",
    "    ' Bộ_luật ': 'BL',\n",
    "    ' Luật ': 'LT',\n",
    "    ' Pháp_lệnh ': 'PL',\n",
    "    ' Lệnh ': 'LH',\n",
    "    ' Nghị_quyết ': 'NQ',\n",
    "    ' Nghị_quyết liên_tịch ': 'NQLT',\n",
    "    ' Nghị_định ': 'NĐ',\n",
    "    ' Quyết_định ': 'QĐ',\n",
    "    ' Thông_tư ': 'TT',\n",
    "    ' Thông_tư liên_tịch ': 'TTLT',\n",
    "    ' Chỉ_thị ': 'CT',\n",
    "}\n",
    "# Xử lý khác\n",
    "for i in range(len(df)):\n",
    "    # Xử lý cột 'Nội dung' (in hoa các đối tượng)\n",
    "    row_vb = df.loc[i, column_vb]\n",
    "    for key, value in type_documents.items():\n",
    "        row_vb = row_vb.replace(key.replace(' ', '').lower(), key)             # viết hoa đầu chữ các tên loại văn bản\n",
    "    df.at[i, column_vb] = row_vb\n",
    "\n",
    "    # Xử lý cột \"Mối quan hệ\" (chuẩn hóa cột 'Mối quan hệ')\n",
    "    row_qh = df.loc[i, column_qh]\n",
    "    row_qh = vb.covert_unicode(row_qh).replace('“', '\"').replace('”', '\"')\n",
    "    row_qh = ViTokenizer.tokenize(row_qh).replace(\" / \", \"/\").replace(\" - \", \"-\")\n",
    "    row_qh = row_qh.replace('bị sửa_đổi , bổ_sung', 'được sửa_đổi , bổ_sung')\n",
    "    row_qh = {key.lstrip().rstrip().capitalize(): [v.lstrip().rstrip() for v in value] for key, value in eval(row_qh).items()}\n",
    "    df.at[i, column_qh] = row_qh\n",
    "\n",
    "\n",
    "\n",
    "# Xuất file csv\n",
    "df.to_csv(\"data/tvpl_processing.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thống kê các tên văn bản có trong văn bản chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_type = {}\n",
    "for i, row in enumerate(df[column_vb]):\n",
    "    for key, value in type_documents.items():\n",
    "        count = row.count(key)\n",
    "        if key not in dict_type:\n",
    "            dict_type[key] = count\n",
    "        else: \n",
    "            dict_type[key] = dict_type[key] + count\n",
    "\n",
    "print(len(dict_type))\n",
    "dict_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xác định các nhãn quan hệ trong tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_list = []\n",
    "\n",
    "for i, row_dict in enumerate(df[column_qh]):\n",
    "    for key in row_dict.keys():\n",
    "        if key not in label_list:\n",
    "            label_list.append(key)\n",
    "\n",
    "label_list = [key for key in label_list]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gán nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/tvpl_processing.csv', encoding='utf-8-sig')\n",
    "# df1 = df.copy()\n",
    "\n",
    "column_vb = 'Nội dung'\n",
    "column_qh = 'Mối quan hệ'\n",
    "\n",
    "label_dict = {\n",
    "    'Được sửa_đổi , bổ_sung': 'DSD',\n",
    "    'Bị thay_thế': 'BTT',\n",
    "    'Dẫn chiếu': 'DC',\n",
    "    'Căn_cứ': 'CC',\n",
    "    'Được hướng_dẫn': 'DHD',\n",
    "    'Hết hiệu_lực': 'HHL',\n",
    "}\n",
    "object_dict = {\n",
    "    ' Hiến_pháp ': 'HP',\n",
    "    ' Bộ_luật ': 'BL',\n",
    "    ' Luật ': 'LT',\n",
    "    ' Pháp_lệnh ': 'PL',\n",
    "    ' Lệnh ': 'LH',\n",
    "    ' Quyết_định ': 'QĐ',\n",
    "    ' Nghị_định ': 'NĐ',\n",
    "    ' Nghị_quyết ': 'NQ',\n",
    "    ' Nghị_quyết liên_tịch ': 'NQLT',\n",
    "    ' Thông_tư ': 'TT',\n",
    "    ' Thông_tư liên_tịch ': 'TTLT',\n",
    "    ' Chỉ_thị ': 'CT',\n",
    "}\n",
    "\n",
    "df[column_qh] = df.apply(lambda x: eval(x[column_qh]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def auto_label(text_str, key, value, row_qh, label_dict):\n",
    "    label = text_str\n",
    "    # pattern = rf'({key})' + r' ((?:(?!ngày|số|này|tại|theo|thì|và)\\w+[ _])+)?(số)? (\\d+/\\d+/[a-zđ]+(?:\\d+|[-\\w]+)+|(?:\\w+[-]\\d+(?:/[\\w\\d]+)+|(?:\\d+[-]\\w+)+|(?:\\d+[/]\\w+(?:[-\\w]+)?)+|\\d+)?( ngày \\d{1,2}(?: tháng |[-]|[/])\\d{1,2}(?: năm |[-]|[/])\\d{4})?'\n",
    "    pattern = rf'({key})' + r' ((?:(?!ngày|số|này|tại|theo|thì|và|[A-ZĐ])\\w+[ _])+)?(số)?\\s?(\\d+?[\\w]+(?:(?:/|-)+(?:\\d|\\w)+)+)?\\s?(ngày \\d{1,2}(?: tháng |[-]|[/])\\d{1,2}(?: năm |[-]|[/])\\d{4})?'\n",
    "    # pattern = rf'({key})((?:(?!ngày|số|này|tại|theo|thì)[^.;()]+\\w+[ _])+)?(số)? (\\d+/\\d+/[a-zđ]+(?:\\d+|[-]\\w+)+|(?:\\w+[-]\\d+)+|(?:\\d+[-]\\w+)+|\\d+)?( ngày \\d{1,2}(?: tháng |[-/])\\d{1,2}(?: năm |[-/])\\d{4})?'\n",
    "    list_objects = re.findall(pattern, text_str)\n",
    "    list_objects = list(set(list_objects))\n",
    "    if list_objects:     \n",
    "        for object in list_objects:\n",
    "            object_tuple = tuple(filter(lambda x: x != '', object))\n",
    "            if len(object_tuple) <= 2:\n",
    "                continue\n",
    "            object = ' '. join(object_tuple).replace('  ', ' ')\n",
    "            if 'này' in object or 'của' in object or object + ' ngày' in text_str:\n",
    "                continue\n",
    "            \n",
    "            if (key == 'Nghị_quyết' or key == 'Thông_tư') and ('Thông_tư liên_tịch' in object or 'Nghị_quyết liên_tịch' in object):\n",
    "                continue\n",
    "            qh = check_relationship(text_str, object, row_qh, label_dict)\n",
    "            object = f' {object} '\n",
    "            label_object = f' <{value} rel=\"{qh}\">' + object + f\"</{value}> \"\n",
    "            \n",
    "            label = label.replace(object, label_object)\n",
    "\n",
    "    return label\n",
    "\n",
    "# check có trong quan hệ\n",
    "def check_relationship(text_str, object, row_qh, label_dict):\n",
    "    cc_check = ['căn_cứ ' + object, 'căn_cứ vào ' + object]\n",
    "    if  any(cc.lower() in text_str.lower() for cc in cc_check):\n",
    "        return 'CC'\n",
    "    \n",
    "    pattern = r'(tại|theo)+ ([^.;]+ )?'+rf'{object}'\n",
    "    if re.search(pattern, text_str):\n",
    "        return 'DC'\n",
    "    \n",
    "    pattern = rf'{object}' + r'( [^.;]+)? được sửa_đổi , bổ_sung '\n",
    "    if re.search(pattern, text_str):\n",
    "        return 'DSD'\n",
    "\n",
    "    \n",
    "    pattern = rf'{object}' + r'( [^.;]+)? hết hiệu_lực '\n",
    "    if re.search(pattern, text_str):\n",
    "        return 'HHL'\n",
    "\n",
    "    for key, list_value in row_qh.items():\n",
    "        for value in list_value:\n",
    "            key_element = re.findall(r'\\d+/\\d+/\\w+(?:-\\w+)?|\\d+/\\w+(?:-\\w+)?|\\d+-\\w+', value)\n",
    "            if key_element:\n",
    "                key_element = key_element[0]\n",
    "            else:\n",
    "                key_element = re.sub(r'\\d+', '', value)\n",
    "            if key_element.lower() in object:\n",
    "                return label_dict[key]\n",
    "    return 'None'\n",
    "\n",
    "\n",
    "# text = 'căn_cứ Nghị_định số 126/2020/nđ-cp ngày 19 tháng 10 năm 2020 của chính_phủ quy_định chi_tiết một_số điều của Luật quản_lí thuế'\n",
    "# key = 'Nghị_định'\n",
    "# value = 'NĐ'\n",
    "# print(auto_label(text, key, value, {}, label_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = df.copy()\n",
    "for i in range(len(df1)):\n",
    "# for i in range(100):\n",
    "    row_vb = df1.loc[i, column_vb]\n",
    "    row_qh = df1.loc[i, column_qh]\n",
    "\n",
    "    line_total = []\n",
    "    line_total.extend(row_vb.splitlines()[0:2])\n",
    "    for line in row_vb.splitlines()[2:]:\n",
    "        for key_object, value_object in object_dict.items():\n",
    "            if key_object in line:    \n",
    "                key_o = key_object.strip()\n",
    "                if key_o == 'Hiến_pháp':\n",
    "                    pattern = rf'({key_o}) (nước cộng_hoà xã_hội chủ_nghĩa việt_nam)? (năm \\d+|\\d+)?'\n",
    "                    objects = re.search(pattern, line)\n",
    "                    if objects:\n",
    "                        objects = objects[0]\n",
    "                        qh = check_relationship(line, objects, row_qh, label_dict)\n",
    "                        label_object = f'<{value_object} rel=\"{qh}\">' + ' ' + objects + ' ' + f\"</{value_object}>\"\n",
    "                        line = line.replace(objects, label_object)\n",
    "                else:\n",
    "                    line = auto_label(line, key_o, value_object, row_qh, label_dict)\n",
    "                     \n",
    "        line_total.append(line)\n",
    "\n",
    "    df1.at[i, column_vb] = '\\n'.join(line_total)\n",
    "\n",
    "\n",
    "# Export data\n",
    "_df = df1\n",
    "for i in range(len(_df)):\n",
    "    with open(f'data/source_test/vb_{i}.xml', 'w', encoding='utf-8') as file:\n",
    "        for line in _df.loc[i, column_vb].splitlines():\n",
    "            file.write(line + '\\n')\n",
    "        \n",
    "    \n",
    "# with open('text.txt', 'w', encoding='utf-8') as file:\n",
    "#     for line in _df.loc[2, column_vb].splitlines():\n",
    "#         file.write(line + '\\n')\n",
    "\n",
    "# Xuất file csv\n",
    "# df1.to_csv(\"data/tvpl_label.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
